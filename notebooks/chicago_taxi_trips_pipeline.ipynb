{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubeflow Pipelines demo using the Chicago taxi trips problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated service account credentials for: [kubeflow-user@kubeflow-demo-256908.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth activate-service-account --key-file=${GOOGLE_APPLICATION_CREDENTIALS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture pip_install_out\n",
    "\n",
    "!pip install pip --upgrade\n",
    "!pip install -r mlpipeline_utils/requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../mlpipeline_utils')\n",
    "import uuid\n",
    "import tempfile\n",
    "\n",
    "import kfp\n",
    "import kfp.gcp\n",
    "\n",
    "from mlpipeline_utils.kfp_components import *\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://kubeflow-demo-256908-dev/...\n",
      "ServiceException: 409 Bucket kubeflow-demo-256908-dev already exists.\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "REGION = 'us-central1'\n",
    "DEV_BUCKET = f'gs://{PROJECT_ID}-dev'\n",
    "!gsutil mb -b on {DEV_BUCKET}\n",
    "BASE_GCS_PATH = os.path.join(DEV_BUCKET, 'demo', 'chicago_taxi_tips')\n",
    "MODEL_MODULE_PATH = os.path.join(BASE_GCS_PATH, 'model.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTILS_IMAGE = kfp.containers.build_image_from_working_dir(\n",
    "    working_dir='../mlpipeline_utils',\n",
    "    base_image=f'gcr.io/{PROJECT_ID}/kfp-base',\n",
    ")\n",
    "UTILS_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_client = kfp.Client()\n",
    "kfp_compiler = kfp.compiler.Compiler()\n",
    "\n",
    "\n",
    "def _get_pipeline_id_by_name(pipeline_name):\n",
    "    next_page_token = ''\n",
    "    while next_page_token is not None:\n",
    "        list_result = kfp_client.list_pipelines(next_page_token).to_dict()\n",
    "        next_page_token = list_result['next_page_token']\n",
    "        for l in list_result['pipelines']:\n",
    "            if l['name'] == pipeline_name:\n",
    "                return l['id']\n",
    "\n",
    "\n",
    "def _delete_pipeline_by_name(pipeline_name):\n",
    "    pipeline_id = _get_pipeline_id_by_name(pipeline_name)\n",
    "    if pipeline_id is not None:\n",
    "        kfp_client.pipelines.delete_pipeline(pipeline_id)\n",
    "\n",
    "\n",
    "def _force_upload_pipeline(pipeline_func):\n",
    "    pipeline_name = pipeline_func._pipeline_name\n",
    "    with tempfile.NamedTemporaryFile(suffix='.zip') as package_file:\n",
    "        kfp.compiler.Compiler().compile(pipeline_func, package_file.name)\n",
    "        _delete_pipeline_by_name(pipeline_name)\n",
    "        kfp_client.upload_pipeline(package_file.name, pipeline_name=pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model module (IMPORTANT!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://chicago_taxi_trips_model.py [Content-Type=text/x-python]...\n",
      "/ [1 files][ 12.4 KiB/ 12.4 KiB]                                                \n",
      "Operation completed over 1 objects/12.4 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp chicago_taxi_trips_model.py {MODEL_MODULE_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='Generate chicago taxi trips dataset',\n",
    "    description='Pipeline to generate and analyze train/eval splits for the Chicago traxi trips problem.'\n",
    ")\n",
    "def chicago_taxi_trips_dataset_pipeline(\n",
    "    examples_output_dir: str,\n",
    "    stats_output_dir: str,\n",
    "    base_sample_rate: float=0.0001,\n",
    "    train_samples_fraction: float=0.75,\n",
    "    temp_dir: str=os.path.join(BASE_GCS_PATH, 'temp'),\n",
    "    project_id: str=PROJECT_ID,\n",
    "    region: str=REGION,\n",
    "    runner: str='DirectRunner',\n",
    "):\n",
    "    workflow_temp_dir = os.path.join(str(temp_dir), '{{workflow.name}}')\n",
    "\n",
    "    base_query = \"\"\"\n",
    "    SELECT\n",
    "        unique_key AS row_id,\n",
    "        pickup_community_area,\n",
    "        fare,\n",
    "        EXTRACT(MONTH FROM trip_start_timestamp) AS trip_start_month,\n",
    "        EXTRACT(HOUR FROM trip_start_timestamp) AS trip_start_hour,\n",
    "        EXTRACT(DAYOFWEEK FROM trip_start_timestamp) AS trip_start_day,\n",
    "        UNIX_SECONDS(trip_start_timestamp) AS trip_start_timestamp,\n",
    "        pickup_latitude,\n",
    "        pickup_longitude,\n",
    "        dropoff_latitude,\n",
    "        dropoff_longitude,\n",
    "        trip_miles,\n",
    "        pickup_census_tract,\n",
    "        dropoff_census_tract,\n",
    "        payment_type,\n",
    "        company,\n",
    "        trip_seconds,\n",
    "        dropoff_community_area,\n",
    "        tips\n",
    "    FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "    \"\"\"\n",
    "\n",
    "    train_eval_examples_op = generate_random_train_eval_examples_from_bq_comp(\n",
    "        name='generate_train_eval_examples',\n",
    "        utils_image=UTILS_IMAGE,\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        temp_dir=workflow_temp_dir,\n",
    "        runner=runner,\n",
    "        base_query=base_query,\n",
    "        base_sample_rate=base_sample_rate,\n",
    "        train_samples_fraction=train_samples_fraction,\n",
    "        output_dir=examples_output_dir,\n",
    "    ).apply(kfp.gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "    train_dataset_stats_op = tfrecord_stats_gen_comp(\n",
    "        name='train_dataset_stats',\n",
    "        utils_image=UTILS_IMAGE,\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        temp_dir=workflow_temp_dir,\n",
    "        runner=runner,\n",
    "        data_location=os.path.join(str(examples_output_dir), 'train', '*.tfrecord.gz'),\n",
    "        output_dir=os.path.join(str(stats_output_dir), 'train'),\n",
    "    ).apply(kfp.gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    train_dataset_stats_op.after(train_eval_examples_op)\n",
    "\n",
    "    eval_dataset_stats_op = tfrecord_stats_gen_comp(\n",
    "        name='eval_dataset_stats',\n",
    "        utils_image=UTILS_IMAGE,\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        temp_dir=workflow_temp_dir,\n",
    "        runner=runner,\n",
    "        data_location=os.path.join(str(examples_output_dir), 'eval', '*.tfrecord.gz'),\n",
    "        output_dir=os.path.join(str(stats_output_dir), 'eval'),\n",
    "    ).apply(kfp.gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    eval_dataset_stats_op.after(train_eval_examples_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit adhoc pipeline run (good for debugging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local runner (heavily undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"Float\" based on the value \"0.0001\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/opt/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"Float\" based on the value \"0.75\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/b7cb13f6-a114-44bb-b4e8-0f7d2037f2e8\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/61d9bdcd-f85c-11e9-9d63-42010a800157\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<kfp._client.Client.create_run_from_pipeline_package.<locals>.RunPipelineResult at 0x7f03ac5d1c18>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = str(uuid.uuid4()).replace('-', '')\n",
    "examples_output_dir = os.path.join(BASE_GCS_PATH, 'datasets', dataset_id, 'examples')\n",
    "stats_output_dir = os.path.join(BASE_GCS_PATH, 'datasets', dataset_id, 'stats')\n",
    "\n",
    "kfp_client.create_run_from_pipeline_func(\n",
    "    chicago_taxi_trips_dataset_pipeline,\n",
    "    arguments={\n",
    "        'project_id': PROJECT_ID,\n",
    "        'region': REGION,\n",
    "        'base_sample_rate': 0.0001,\n",
    "        'train_samples_fraction': 0.75,\n",
    "        'runner': 'DirectRunner',\n",
    "        'examples_output_dir': examples_output_dir,\n",
    "        'stats_output_dir': stats_output_dir\n",
    "    },\n",
    "    experiment_name='Chicago taxi trips dataset',\n",
    "    run_name=f'train_eval_examples_local_{dataset_id}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataflow runner (for when we need to scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"Float\" based on the value \"0.0001\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/opt/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"Float\" based on the value \"0.75\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/b7cb13f6-a114-44bb-b4e8-0f7d2037f2e8\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/c3cab4d4-f7c9-11e9-b7d5-42010a800003\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<kfp._client.Client.create_run_from_pipeline_package.<locals>.RunPipelineResult at 0x7fcfd747f898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = str(uuid.uuid4()).replace('-', '')\n",
    "examples_output_dir = os.path.join(BASE_GCS_PATH, 'datasets', dataset_id, 'examples')\n",
    "stats_output_dir = os.path.join(BASE_GCS_PATH, 'datasets', dataset_id, 'stats')\n",
    "\n",
    "kfp_client.create_run_from_pipeline_func(\n",
    "    chicago_taxi_trips_dataset_pipeline,\n",
    "    arguments={\n",
    "        'project_id': PROJECT_ID,\n",
    "        'region': REGION,\n",
    "        'base_sample_rate': 0.1,\n",
    "        'train_samples_fraction': 0.75,\n",
    "        'runner': 'DataflowRunner',\n",
    "        'examples_output_dir': examples_output_dir,\n",
    "        'stats_output_dir': stats_output_dir\n",
    "    },\n",
    "    experiment_name='Chicago taxi trips dataset',\n",
    "    run_name=f'train_eval_examples_dataflow_{dataset_id}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload final pipeline iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Pipeline link <a href=/pipeline/#/pipelines/details/f0a4cda0-d05c-453a-9ffe-6fa4be68fc96>here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_force_upload_pipeline(chicago_taxi_trips_dataset_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tfma(\n",
    "    eval_savedmodel_dir: str,\n",
    "    data_location: str,\n",
    "    output_dir: str\n",
    "):\n",
    "    import logging\n",
    "    import tensorflow_model_analysis as tfma\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    eval_shared_model = tfma.default_eval_shared_model(\n",
    "        eval_saved_model_path=eval_savedmodel_dir,\n",
    "        add_metrics_callbacks=[\n",
    "            tfma.post_export_metrics.auc_plots(),\n",
    "            tfma.post_export_metrics.calibration_plot_and_prediction_histogram()\n",
    "        ]\n",
    "    )\n",
    "    eval_result = tfma.run_model_analysis(\n",
    "        eval_shared_model=eval_shared_model,\n",
    "        data_location=data_location,\n",
    "        file_format='tfrecords',\n",
    "        slice_spec=[\n",
    "            tfma.slicer.SingleSliceSpec(),\n",
    "            tfma.slicer.SingleSliceSpec(columns=['trip_start_hour']),\n",
    "        ],\n",
    "        output_path=output_dir\n",
    "    )\n",
    "\n",
    "\n",
    "run_tfma_comp = kfp.components.func_to_container_op(run_tfma, base_image=UTILS_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='Build Chicago taxi trips model',\n",
    "    description='Build a model for the Chicago taxi trips problem.'\n",
    ")\n",
    "def chicago_taxi_trips_model_pipeline(\n",
    "    train_examples_dir: str,\n",
    "    eval_examples_dir: str,\n",
    "    examples_schema_path: str,\n",
    "    model_dir: str,\n",
    "    tfma_output_dir: str='',\n",
    "    module_path: str=MODEL_MODULE_PATH,\n",
    "    train_steps: int=10000,\n",
    "    eval_steps: int=1000,\n",
    "    temp_dir: str=os.path.join(BASE_GCS_PATH, 'temp'),\n",
    "    project_id: str=PROJECT_ID,\n",
    "    region: str=REGION,\n",
    "    runner: str='DirectRunner'\n",
    "):\n",
    "    workflow_temp_dir = os.path.join(str(temp_dir), '{{workflow.name}}')\n",
    "    transformed_examples_base_dir = os.path.join(workflow_temp_dir, 'transformed_examples')\n",
    "    train_transformed_examples_dir = os.path.join(transformed_examples_base_dir, 'train')\n",
    "    eval_transformed_examples_dir = os.path.join(transformed_examples_base_dir, 'eval')\n",
    "    transform_fn_dir = os.path.join(workflow_temp_dir, 'transform_fn')\n",
    "\n",
    "    train_tft_analyze_and_transform_op = tft_analyze_and_transform_comp(\n",
    "        name='train-tft-analyze-and-transform',\n",
    "        utils_image=UTILS_IMAGE,\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        temp_dir=workflow_temp_dir,\n",
    "        raw_examples_path=os.path.join(str(train_examples_dir), '*.tfrecord.gz'),\n",
    "        raw_examples_schema_path=examples_schema_path,\n",
    "        preprocessing_module_path=module_path,\n",
    "        transformed_examples_path_prefix=os.path.join(str(train_transformed_examples_dir), 'part'),\n",
    "        transform_fn_dir=transform_fn_dir,\n",
    "        runner=runner\n",
    "    ).apply(kfp.gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "    eval_tft_transform_op = tft_transform_comp(\n",
    "        name='eval-tft-transform',\n",
    "        utils_image=UTILS_IMAGE,\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        temp_dir=workflow_temp_dir,\n",
    "        raw_examples_path=os.path.join(str(eval_examples_dir), '*.tfrecord.gz'),\n",
    "        raw_examples_schema_path=examples_schema_path,\n",
    "        transformed_examples_path_prefix=os.path.join(str(eval_transformed_examples_dir), 'part'),\n",
    "        transform_fn_dir=transform_fn_dir,\n",
    "        runner=runner\n",
    "    ).apply(kfp.gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    eval_tft_transform_op.after(train_tft_analyze_and_transform_op)\n",
    "\n",
    "    trainer_op = tf_estimator_trainer_comp(\n",
    "        name='tf-train-and-evaluate',\n",
    "        utils_image=UTILS_IMAGE,\n",
    "        module_path=str(module_path),\n",
    "        model_dir=model_dir,\n",
    "        hparams=json.dumps({\n",
    "            'train_files': os.path.join(str(train_transformed_examples_dir), '*.tfrecord.gz'),\n",
    "            'eval_files': os.path.join(str(eval_transformed_examples_dir), '*.tfrecord.gz'),\n",
    "            'transform_output': str(transform_fn_dir),\n",
    "            'train_steps': str(train_steps),\n",
    "            'eval_steps': str(eval_steps),\n",
    "            'schema_path': str(examples_schema_path),\n",
    "            'warm_start_from': None,\n",
    "        }),\n",
    "        metrics_to_export=' '.join([\n",
    "            'auc', 'auc_precision_recall', 'loss'\n",
    "        ])\n",
    "    ).apply(kfp.gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "    trainer_op.after(train_tft_analyze_and_transform_op)\n",
    "    trainer_op.after(eval_tft_transform_op)\n",
    "\n",
    "    with kfp.dsl.Condition(tfma_output_dir != ''):\n",
    "        run_tfma_op = run_tfma_comp(\n",
    "            eval_savedmodel_dir=trainer_op.outputs['eval_savedmodel_dir'],\n",
    "            data_location=os.path.join(str(eval_examples_dir), '*.tfrecord.gz'),\n",
    "            output_dir=str(tfma_output_dir)\n",
    "        ).apply(kfp.gcp.use_gcp_secret('user-gcp-sa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit adhoc pipeline run (good for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"10000\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/opt/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"1000\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/5ce6a5d0-6e08-430e-893c-05468c2c4fec\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/1b5f3a38-f835-11e9-9d63-42010a800157\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<kfp._client.Client.create_run_from_pipeline_package.<locals>.RunPipelineResult at 0x7f3fd5a51898>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = '16d4f29d89c240a19e4bf61fed07505f'  # big scale dataset\n",
    "# dataset_id = 'e500ca33e46846f1ac4367444e314657'  # small scale dataset\n",
    "examples_output_dir = os.path.join(BASE_GCS_PATH, 'datasets', dataset_id, 'examples')\n",
    "stats_output_dir = os.path.join(BASE_GCS_PATH, 'datasets', dataset_id, 'stats')\n",
    "model_id = str(uuid.uuid4()).replace('-', '')\n",
    "\n",
    "kfp_client.create_run_from_pipeline_func(\n",
    "    chicago_taxi_trips_model_pipeline, \n",
    "    arguments={\n",
    "        'project_id': PROJECT_ID,\n",
    "        'region': REGION,\n",
    "#         'runner': 'DirectRunner',\n",
    "        'runner': 'DataflowRunner',\n",
    "        'train_examples_dir': os.path.join(examples_output_dir, 'train'),\n",
    "        'eval_examples_dir': os.path.join(examples_output_dir, 'eval'),\n",
    "        'examples_schema_path': os.path.join(stats_output_dir, 'train', 'inferred_schema.pb2'),\n",
    "        'model_dir': os.path.join(BASE_GCS_PATH, 'models', model_id),\n",
    "        'train_steps': 1000000,\n",
    "        'eval_steps': 1000,\n",
    "        'tfma_output_dir': os.path.join(BASE_GCS_PATH, 'tfma', model_id)\n",
    "    },\n",
    "    experiment_name='Chicago taxi trips modeling',\n",
    "    run_name=f'train_chicago_taxi_trips_model_{model_id}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload final pipeline iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Pipeline link <a href=/pipeline/#/pipelines/details/e84b9edb-0164-456a-9079-8a8de36c9764>here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_force_upload_pipeline(chicago_taxi_trips_model_pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
