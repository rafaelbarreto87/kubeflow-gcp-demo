{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: copied and adapted from https://github.com/mkneierV/test_notebooks/blob/master/demo_data_prep.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# default parameters\n",
    "\n",
    "RUN_LOCAL = True\n",
    "ROOT_DIR = 'temp/papermill_demo'\n",
    "PROJECT = 'kubeflow-demo-256908'\n",
    "BUCKET = 'gs://{}-dev'.format(PROJECT)\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install matplotlib --upgrade\n",
    "!pip install pandas --upgrade\n",
    "!pip install apache-beam[gcp]==2.16.0\n",
    "!pip install six==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import apache_beam as beam\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df\n",
    "\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    mother_race,\n",
    "    plurality,\n",
    "    gestation_weeks\n",
    "FROM\n",
    "    publicdata.samples.natality\n",
    "WHERE year BETWEEN 1980 AND 2004\n",
    "    AND weight_pounds > 0\n",
    "    AND mother_age > 0\n",
    "    AND plurality > 0\n",
    "    AND gestation_weeks > 0\n",
    "    AND month > 0\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df['gestation_weeks'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"weight_pounds\", \"is_male\", \"mother_age\", \"mother_race\", \"plurality\", \"gestation_weeks\"]\n",
    "\n",
    "\n",
    "def get_source_query(step):\n",
    "    train_years = (1980,2004)\n",
    "    eval_years  = (2005,2007)\n",
    "    test_years  = (2008, 2008)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "      weight_pounds,\n",
    "      is_male,\n",
    "      mother_age,\n",
    "      mother_race,\n",
    "      plurality,\n",
    "      gestation_weeks\n",
    "    FROM\n",
    "      publicdata.samples.natality\n",
    "    WHERE year BETWEEN {} AND {}\n",
    "      AND weight_pounds > 0\n",
    "      AND mother_age > 0\n",
    "      AND plurality > 0\n",
    "      AND gestation_weeks > 0\n",
    "      AND month > 0\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "    \n",
    "    if step == 'eval':\n",
    "        source_query = query.format(*eval_years)\n",
    "    elif step == 'test':\n",
    "        source_query = query.format(*test_years)\n",
    "    elif step == \"train\":\n",
    "        source_query = query.format(*train_years)\n",
    "    else:\n",
    "        raise ValueError(\"step value of {} must be one of 'train', 'eval', 'test'\".format(step))\n",
    "    return source_query\n",
    "\n",
    "\n",
    "\n",
    "def prep_bq_row(bq_row):\n",
    "    # modify opaque numeric race code into human-readable data\n",
    "    races = dict(zip([1,2,3,4,5,6,7,18,28,39,48],\n",
    "                     ['White', 'Black', 'American Indian', 'Chinese', \n",
    "                      'Japanese', 'Hawaiian', 'Filipino',\n",
    "                      'Asian Indian', 'Korean', 'Samaon', 'Vietnamese']))\n",
    "    result = {} \n",
    "    \n",
    "    for feature_name in bq_row.keys():\n",
    "        result[feature_name] = str(bq_row[feature_name])\n",
    "\n",
    "    if 'mother_race' in bq_row and bq_row['mother_race'] in races:\n",
    "        result['mother_race'] = races[bq_row['mother_race']]\n",
    "    else:\n",
    "        result['mother_race'] = 'Unknown'\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def to_csv_string(bq_dict):\n",
    "    output = []\n",
    "    for f in FEATURES:\n",
    "        output.append(bq_dict[f])\n",
    "        \n",
    "    return \",\".join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and run distributed pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(BUCKET, ROOT_DIR)\n",
    "TRANSFORMED_DATA_DIR = os.path.join(OUTPUT_DIR,'transformed')\n",
    "\n",
    "pipeline_options = beam.pipeline.PipelineOptions(flags=[], **{\n",
    "    'runner': 'DirectRunner' if RUN_LOCAL == True else 'DataflowRunner',\n",
    "    'project': PROJECT,\n",
    "    'region': REGION,\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "})\n",
    "\n",
    "\n",
    "with beam.Pipeline(options=pipeline_options) as pipeline:            \n",
    "    for step in (\"train\", \"eval\", \"test\"):\n",
    "        source_query = get_source_query(step)\n",
    "        data = (\n",
    "            pipeline\n",
    "            | '{} - Read Data from BigQuery'.format(step) >> beam.io.Read(\n",
    "                beam.io.BigQuerySource(query=source_query, use_standard_sql=True))\n",
    "            | '{} - Clean up Data'.format(step) >> beam.Map(prep_bq_row)\n",
    "            | '{} - Prepare for csv'.format(step) >> beam.Map(to_csv_string)\n",
    "            | '{} - Write Transformed Data'.format(step) >> beam.io.WriteToText(\n",
    "                file_path_prefix=os.path.join(TRANSFORMED_DATA_DIR, step, step),\n",
    "                file_name_suffix=\".csv\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {TRANSFORMED_DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\n",
    "    os.path.join(TRANSFORMED_DATA_DIR, 'eval', 'eval-00000-of-00001.csv'),\n",
    "    names=[\n",
    "        'weight_pounds',\n",
    "        'is_male',\n",
    "        'mother_age',\n",
    "        'mother_race',\n",
    "        'plurality',\n",
    "        'gestation_weeks'\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
